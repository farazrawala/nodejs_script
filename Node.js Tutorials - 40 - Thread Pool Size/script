 hello again In the last video, we discussed libue's thread pool and how the main thread uses it to delegate work for asynchronous operations like pbk df2.
 (((((((("welcome back in the previous video we learned about libue's thread pool and how the main thread offloads some of the async methods like pbk df2 into the thread pool.

pbkdf2 was run three times, and each time it completed in parallel, thus there must be at least three threads available.
(((((((("we executed pbkdf2 three times which all executed in parallel indicating we have at least three threads in the pool.

However, it is unclear how many threads exist.
(((((((("but the question is how many threads are there in total.

OK, in that case, let's see what the third experiment reveals.
In the third trial, I'll have the maximum number of calls set to 4.
Yes, we do node indexing.
many times. 
(((((((("well let's find out with this third experiment.
for experiment 3 I'm going to set max calls equal to 4.
we run node index.
a couple of times.

each of the four hashers has about the same time.
There is some variation, but generally speaking, the figure is close to 300. 
(((((((("and we see almost the same time for all four hashers.
there is slight difference but on an average it's close to 300.

Max calls will now be limited to 5.
Do a node index.
And right once you can tell that there is a distinction.
(((((((("Let's now change Max calls to 5.
run node index.
and straight away you can see there is something different.

On average, hash 5 takes roughly twice as long as hash 0, 1, 2, 3, and 4.
Which means one thing and one thing alone There are four threads in Libby's thread pool. 
(((((((("hash 5 takes nearly twice the amount of time as the first four on average.
which can only mean one thing Libby's thread pool has four threads.

The first four runs of pbkdf2 run in parallel and are finished almost simultaneously when run five times.
(((((((("when we execute pbkdf2 five times the first four each take their own thread and complete in nearly the same time.

The fifth call, however, must wait until a thread becomes available.
When hash 1 completes, hash 5 runs on the thread and completes, doubling the total time required. 
(((((((("the fifth call however has to wait for a thread to be free.
when hash 1 is complete hash 5 runs on the thread and finishes resulting in twice the amount of time taken in total.

Consequently, libuey's thread pool initially has four threads.
The third experiment will serve as the basis for this conclusion.
(((((((("so libuey's thread pool has four threads by default.
this will be our inference from experiment number three.

It's natural to wonder if higher performance is possible by increasing the thread pool size and hence the amount of simultaneous pbk df2 calls.
To put it simply, yeah.
(((((((("now you might ask can we increase the number of threads in the thread pool so that more calls to pbk df2 can run in parallel leading to better performance.
well the answer is yes.

This leads us to our fourth experiment.
In order to do this test, we will expand the available pool of threads.
That may be accomplished by modifying an environment variable for the running process. 
(((((((("and that brings us to experiment number four.
for this experiment we will increase the thread pool size.
the way to do that is by setting a process environment variable.

EnVy underscore UV underscore thread pool size underscore process.
OK, let's go with 5 for now.
when we run node index again
(((((((("Process dot EnVy dot UV underscore thread pool underscore size.
let's set it to 5 for now.
if we rerun node index.

As can be seen, the time required for the fifth hash is not double that of the preceding hashes.
Limit incoming calls to a maximum of 6.Perform a node index.
(((((((("you can see the fifth hash takes almost the same time and not twice as much as the other hashes.
set max calls to 6.run node index.

It's a double increase to the sixth hash, now.
increase the amount of thread pulls to 6.
(((((((("and now the sixth hash takes twice as much.
update thread pull size to 6.

Moreover, hash 6 now only requires half the time it did previously.
The overall time required to perform numerous calls of pvk df2 can be reduced by expanding the thread pool. 
(((((((("and we see hash 6 doesn't take twice as much anymore.
in this way by increasing the thread pool size we are able to improve the total time taken to run multiple calls of pvk df2.

and we will draw this conclusion after doing Experiment 4.
Just remember this one thing when you increase the size of the thread pool. 
(((((((("and this will be our inference from experiment number four.
and there is one important point to keep in mind when increasing the thread pool size.

The average time for a method to execute grows proportionally larger if you increase it beyond the number of CPU cores your system has.
It leads us to the following test.
(((((((("if you increase it beyond the number of CPU cores your machine has the average time taken per method execution also increases.
which brings us to the next experiment.

Experiment 5 will have a size adjustment of 8.
And Max dials the number 8, too.
If the node index is run again. 
(((((((("for experiment 5 I'm going to change size to 8.
and Max calls also to 8.
if we rerun node index.

All eight hashes still take around 300 milliseconds on average to calculate. 
(((((((("we see all eight hashes still consume approximately the same time 300 milliseconds on average.

If we restart node index, I will increase the thread pull size to 16 and the maximum number of calls to 16.
(((((((("now though I'm going to change thread pull size to 16 and Max calls to 16 if we rerun node index.

As you can see, there is little difference in time required for any of the 16 hashes.
treble the time of the previous run, coming in at 550â€“600 ms.
(((((((("you can see almost all the 16 hashes take the same amount of time as the other.
it is around 550 to 600 milliseconds.
 which is double the previous run.

For my MacBook, which has eight processor cores, this is because the operating system must balance sixteen simultaneous threads.
(((((((("and this is because the operating system has to juggle 16 threads across 8 CPU cores which is the case for my MacBook.

Let me provide an illustration to clarify the situation for you.
Actually, my MacBook has ten cores, but two of them are efficiency cores, and I'm not sure if they're actually useful.js employs them in the same manner.
(((((((("let me help you understand with a visual representation.
now my MacBook has eight cores it has 10but two are efficiency cores which to be honest I'm not sure if node.js makes use of them the same way.

When there is just one opportunity to use pbk df2, One core is needed, which necessitates one thread.
About 270 ms is needed for this.
when the thread pull size is increased to 8.
(((((((("when we have only one call to pbk df2 It takes one thread which takes one core.
this takes approximately 270milliseconds.
when we change the thread pull size to 8.

and up to eight phone calls.
Each invocation consumes one thread, and hence one CPU core.
Each call will still take around 270 ms as a result of this.
(((((((("and number of calls to 8.
each call takes one thread which in turn takes one core.
this will still result in approximately 270 milliseconds for each call.

however now with 16 threads and 16 pbk df2 calls.
We only use one thread per phone call.
However, the OS must balance 16 threads over 8 CPU cores.
(((((((("now though when there are 16 threads and16 pbk df2 calls.
we have one thread per call.
but the operating system has to juggle16 threads across eight cores.

The OS scheduler will juggle threads to make sure they all get enough processing time.
This means that 16 threads will have to share 8 processors. 
(((((((("and the way the OS scheduler does this is to switch between threads ensuring they all get 
equal amount of time.
and because of this 16 threads now have to share eight cores.

As a direct consequence, each pvk df2 call now takes twice as long.
This explains why we now see 550600ms, rather than the 270300ms we saw when we had less threads than CPU cores.
(((((((("this results in twice the amount of time for each pvk df2 call.
this is the reason we see 550 to 600milliseconds instead of 270 to 300milliseconds when we had fewer threads than CPU cores.

Based on the results of experiment 5, we can conclude that raising the thread pull size can improve speed, but that doing so is constrained by the number of available CPU cores.
(((((((("so increasing the thread pull size can help with performance but that is limited by the number of available CPU cores this will be our inference from experiment number five.

If you're using Node.js's async methods, you should now have a better understanding of how Libby's threat pool facilitates their execution.
(((((((("hopefully you're now able to see under the hood how Libby's threat pool helps execute some of the async methods innode.js.

Now hold on, you might be wondering why I only mentioned certain asynchronous techniques and not all of them.
in that case, let's talk about it in the following video.
(((((((("now hang on why do I say some of the async methods why not all async methods.
well let's discuss that in the next video.

See you in the next video, and thanks for watching! If you like what you see, please hit the like button, and don't forget to subscribe to the channel.
(((((((("thank you for watching and if you're enjoying the videos please do leave alike And subscribe to the channel I'll see you in the next one"
