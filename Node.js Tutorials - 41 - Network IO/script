"welcome back.
over the past two videos we've run five different experiments to understand the role of libuey's thread pool when executing async methods like read file and pbkdf2.
in this video I want to stay on the same topic of Liberty and async methods but highlight a different point.
and I'll do that with our next experiment.
for experiment 6 we're going to use a different async method.
this time one that involves the network io.
first comment out the crypto module import.
and the call to pvkdf2.
comment out the thread pool size as well.
instead import the https module.
https is a secure version of the HTTP module we've already seen.
the method we are going to invoke is the request method that makes a request to an endpoint.
let me copy paste the code to save us some time.
request accepts a URL and we are making a request to google.com.
the second argument is a call back function which gets access to the response.
we can add listeners to the data and end events.
within the end event listener.
we are going to log the time taken for the request.
very similar to what we were doing with pbk df2.
finally we end the request.
and this call to request is placed inside the for Loop.
let's now run this code with different values of Max calls.
let's start with one.
when we run node index.
we see the request takes approximately 200 milliseconds.
let's now change Max calls to do.
run node index.
and the average is now in the range of 200 to 300 milliseconds.
let's now change Max calls to 4.
rerun node index.
and the average again lies in the range of 200 to 300 milliseconds.
let's bump it up to six.
And six if you can recollect is larger than the default thread pool size.
run the code.
and we see the average is still between200 and 300 milliseconds.
finally let's change Max calls to 12.
we run.
and surprisingly the average is still between 200 and 300 milliseconds.
based on this experiment we can infer the following two points.
First.
although both crypto.pbkdf2 and https dot request are asynchronous https dot request method does not seem to use the thread pool.
we can infer this by noticing that the average time Remains the Same for one request or six requests or even 12 requests.
if thread pool was involved we should have seen a larger average time for more than four requests which we did not.
second https dot request does not seem to be affected by the number of CPU cores either.
even when running 12 requests at a time.
the average time was the same as running one request.
hope fully this makes sense.
and let me tell you this inference is infact true.
https dot request is a network input output operation and not a CPU bound operation.
it does not use the thread pool.
instead delegates the work to the operating system kernel and whenever possible it will pull the kernel and seeif the request has completed.
this is the reason we see nearly thesame request time when we have 1 4 oreven 12 different requests.
all right if this is clear we can conclude this video with the following points.
in node.js async methods are handled by libue.
but they are handled in one of two different ways.
either the native async mechanism or the thread pool.
whenever possible libuv will use native async mechanisms in the operating system so as to avoid blocking the main thread.
since this is part of the kernel there is a different mechanism for each operating system we have e-pol for Linux KQ for Mac OSand IO completion port on Windows.
relying on Native async mechanisms makes node scalable as the only limitation is the operating system kernel.
example of this is a network i o operation on the other hand.
if there is no native async support and the task is file IO or CPU intensive.
Library uses the thread pool to avoid blocking the main thread.
although the thread pull preserves asynchronicity with respect to node'smain thread it can still become a bottle neck if all threads are busy.
I hope you now have a clear understanding of how async methods are handled under the hood in node.js.
thank you for watching please do consider subscribing to the channel and I'll see you in the next one"



